{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìö GraphRecall Book Ingestion Pipeline\n",
        "\n",
        "**All-in-one notebook**: PDF ‚Üí Marker OCR ‚Üí Chunking ‚Üí API Ingestion\n",
        "\n",
        "This notebook is a **backdoor** into GraphRecall. It:\n",
        "1. üìÑ Converts PDF to Markdown using Marker (GPU-accelerated)\n",
        "2. ‚úÇÔ∏è Chunks the markdown with image-aware, heading-preserving chunker\n",
        "3. üß† Sends chunks to your GraphRecall backend API for full processing\n",
        "4. üìä Extracts concepts, builds knowledge graph, generates flashcards & quizzes\n",
        "\n",
        "**Requirements:**\n",
        "- Colab GPU runtime (T4 or better)\n",
        "- Your GraphRecall backend URL and auth token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install marker-pdf requests -q\n",
        "print(\"‚úÖ Dependencies installed!\")\n",
        "print(\"‚ÑπÔ∏è If this is a reused runtime, restart after installs to avoid binary mismatch issues.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Configuration\n",
        "\n",
        "Set your GraphRecall backend URL and authentication details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ‚öôÔ∏è CONFIGURATION - Edit these values\n",
        "# ============================================================\n",
        "\n",
        "# Your GraphRecall backend URL (no trailing slash)\n",
        "BACKEND_URL = \"https://your-graphrecall-backend.com\"  # ‚¨ÖÔ∏è EDIT THIS\n",
        "\n",
        "# Auth: paste your Google OAuth access token here.\n",
        "# Get it from: browser DevTools > Application > Cookies > access_token\n",
        "AUTH_TOKEN = \"\"  # ‚¨ÖÔ∏è PASTE YOUR TOKEN\n",
        "\n",
        "# Book metadata\n",
        "BOOK_TITLE = \"\"  # ‚¨ÖÔ∏è e.g., \"Introduction to Machine Learning\"\n",
        "\n",
        "# Chunking config\n",
        "CHUNK_SIZE = 1400  # Max chars per chunk\n",
        "OVERLAP_RATIO = 0.15  # 15% overlap between chunks\n",
        "\n",
        "# Processing options\n",
        "SKIP_REVIEW = True  # Auto-approve concepts (recommended for books)\n",
        "\n",
        "# ============================================================\n",
        "\n",
        "import requests\n",
        "\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {AUTH_TOKEN}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "# Verify connection\n",
        "try:\n",
        "    resp = requests.get(f\"{BACKEND_URL}/api/v2/health\", headers=HEADERS, timeout=10)\n",
        "    if resp.status_code == 200:\n",
        "        print(f\"‚úÖ Connected to GraphRecall at {BACKEND_URL}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Backend returned status {resp.status_code}\")\n",
        "        print(f\"   Response: {resp.text[:200]}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Cannot reach backend: {e}\")\n",
        "    print(\"   Make sure your backend is running and the URL is correct.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Upload PDF & Run Marker OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU. Go to Runtime > Change runtime type > GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload PDF\n",
        "UPLOAD_METHOD = \"direct\"  # Change to \"drive\" for Google Drive\n",
        "\n",
        "if UPLOAD_METHOD == \"direct\":\n",
        "    from google.colab import files\n",
        "    print(\"üìÅ Select your PDF file...\")\n",
        "    uploaded = files.upload()\n",
        "    PDF_PATH = list(uploaded.keys())[0]\n",
        "    if not BOOK_TITLE:\n",
        "        BOOK_TITLE = PDF_PATH.rsplit('.', 1)[0]\n",
        "    print(f\"‚úÖ Uploaded: {PDF_PATH}\")\n",
        "else:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    PDF_PATH = \"/content/drive/MyDrive/Your_Book.pdf\"  # ‚¨ÖÔ∏è EDIT THIS\n",
        "    if not BOOK_TITLE:\n",
        "        BOOK_TITLE = PDF_PATH.rsplit('/', 1)[-1].rsplit('.', 1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import time\nfrom pathlib import Path\nfrom PIL import Image\n\nfrom marker.converters.pdf import PdfConverter\nfrom marker.models import create_model_dict\nfrom marker.output import text_from_rendered\n\n# Setup paths\npdf_path = Path(PDF_PATH)\noutput_dir = Path(f\"/content/{pdf_path.stem}_output\")\nimages_dir = output_dir / \"images\"\nmd_path = output_dir / f\"{pdf_path.stem}.md\"\n\n# --- RESUME / ZIP LOAD LOGIC ---\n# If you have a zip file from a previous session, unzip it to /content/ first.\nif output_dir.exists() and md_path.exists() and images_dir.exists() and any(images_dir.iterdir()):\n    print(f\"‚ôªÔ∏è Found existing processed data in {output_dir}\")\n    print(\"   Skipping OCR and re-using existing extraction...\")\n    markdown_text = md_path.read_text(encoding=\"utf-8\")\n    image_count = len(list(images_dir.glob(\"*\")))\n    print(f\"   Loaded {len(markdown_text):,} chars and {image_count} images.\")\nelse:\n    # --- RUN NEW OCR ---\n    print(f\"üìñ Processing: {pdf_path.name} ({pdf_path.stat().st_size / 1024 / 1024:.1f} MB)\")\n    print(\"-\" * 50)\n\n    start_time = time.time()\n\n    print(\"üîß Loading OCR models...\")\n    model_dict = create_model_dict()\n    converter = PdfConverter(artifact_dict=model_dict)\n\n    print(\"üìù Extracting text and images...\")\n    rendered = converter(str(pdf_path))\n    markdown_text, _, images = text_from_rendered(rendered)\n\n    elapsed = time.time() - start_time\n    print(f\"‚úÖ OCR complete in {elapsed:.1f}s\")\n    print(f\"   Text: {len(markdown_text):,} chars | Images: {len(images) if images else 0}\")\n\n    # Create directories\n    output_dir.mkdir(parents=True, exist_ok=True)\n    images_dir.mkdir(parents=True, exist_ok=True)\n\n    # --- ROBUST IMAGE SAVING ---\n    saved_count = 0\n    failed_count = 0\n    renamed_images = {}\n\n    def _save_png_fallback(img_obj, original_path):\n        \"\"\"Fallback for Colab/Pillow JPEG-save incompatibilities.\"\"\"\n        png_path = original_path.with_suffix(\".png\")\n\n        if hasattr(img_obj, \"tobytes\"):\n            try:\n                png_path.write_bytes(img_obj.tobytes(\"png\"))\n                return png_path\n            except Exception:\n                pass\n\n        pil_obj = getattr(img_obj, \"image\", img_obj)\n        if not isinstance(pil_obj, Image.Image):\n            pil_obj = Image.frombytes(pil_obj.mode, pil_obj.size, pil_obj.tobytes())\n        pil_obj.convert(\"RGB\").save(str(png_path), format=\"PNG\")\n        return png_path\n\n    if images:\n        for img_name, img_data in images.items():\n            img_path = images_dir / img_name\n            try:\n                # Extract clean PIL Image from Marker/Surya wrappers\n                pil_img = img_data\n                if hasattr(img_data, \"image\"):\n                    pil_img = img_data.image\n                elif hasattr(img_data, \"to_pil\"):\n                    pil_img = img_data.to_pil()\n\n                # Save without extra arguments to avoid wrapper signature issues\n                if hasattr(pil_img, \"save\"):\n                    try:\n                        pil_img.copy().save(str(img_path))\n                    except TypeError as save_err:\n                        if \"at most 16 arguments (17 given)\" not in str(save_err):\n                            raise\n                        fallback_path = _save_png_fallback(pil_img, img_path)\n                        if fallback_path.name != img_name:\n                            renamed_images[img_name] = fallback_path.name\n                    saved_count += 1\n                elif isinstance(img_data, (bytes, bytearray)):\n                    img_path.write_bytes(bytes(img_data))\n                    saved_count += 1\n                else:\n                    with open(img_path, \"wb\") as f:\n                        f.write(bytes(img_data))\n                    saved_count += 1\n\n            except Exception as e:\n                # If the file exists despite an error, count it as success\n                if img_path.exists():\n                    saved_count += 1\n                else:\n                    failed_count += 1\n                    print(f\"  ‚ö†Ô∏è Failed to save {img_name}: {e}\")\n\n        if renamed_images:\n            for old_name, new_name in renamed_images.items():\n                markdown_text = markdown_text.replace(old_name, new_name)\n            print(f\"   Rewrote {len(renamed_images)} markdown image refs to PNG fallback\")\n\n        print(f\"   Saved {saved_count} images to {images_dir}\")\n        if failed_count:\n            print(f\"   ‚ö†Ô∏è {failed_count} images failed (non-critical, text extraction still works)\")\n\n    # Save markdown\n    md_path.write_text(markdown_text, encoding=\"utf-8\")\n    print(f\"   Saved markdown to {md_path}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Chunk the Book\n",
        "\n",
        "Uses GraphRecall's image-aware BookChunker: detects figures, preserves headings, smart overlap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Optional\n",
        "\n",
        "# ============================================================\n",
        "# BookChunker (copied from backend/services/book_chunker.py)\n",
        "# ============================================================\n",
        "\n",
        "IMAGE_PATTERN = re.compile(r\"!\\[[^\\]]*\\]\\((?P<path>[^)]+)\\)\")\n",
        "CAPTION_PATTERN = re.compile(r\"^(Figure|Fig\\.?|FIGURE)\\s+[\\w\\.\\-]+[:\\.']?\\s*(?P<caption>.+)$\")\n",
        "\n",
        "@dataclass\n",
        "class ImageInfo:\n",
        "    filename: str\n",
        "    caption: Optional[str]\n",
        "    page: Optional[int]\n",
        "    url: Optional[str] = None\n",
        "\n",
        "@dataclass\n",
        "class Chunk:\n",
        "    index: int\n",
        "    text: str\n",
        "    images: List[ImageInfo] = field(default_factory=list)\n",
        "    headings: List[str] = field(default_factory=list)\n",
        "\n",
        "class BookChunker:\n",
        "    def __init__(self, max_chars=1400, overlap_ratio=0.15):\n",
        "        self.max_chars = max_chars\n",
        "        self.overlap_ratio = overlap_ratio\n",
        "\n",
        "    def chunk_markdown(self, md_path, images_dir):\n",
        "        lines = md_path.read_text(encoding=\"utf-8\").splitlines()\n",
        "        return self._chunk_lines(lines, images_dir)\n",
        "\n",
        "    def _chunk_lines(self, lines, images_dir):\n",
        "        units = []\n",
        "        current_para = []\n",
        "        heading_stack = []\n",
        "\n",
        "        def flush_para():\n",
        "            if current_para:\n",
        "                text = \"\\n\".join(current_para).strip()\n",
        "                if text:\n",
        "                    units.append({\"type\": \"text\", \"text\": text, \"headings\": heading_stack.copy()})\n",
        "                current_para.clear()\n",
        "\n",
        "        for idx, line in enumerate(lines):\n",
        "            stripped = line.strip()\n",
        "            if stripped.startswith(\"#\"):\n",
        "                flush_para()\n",
        "                level = len(stripped) - len(stripped.lstrip(\"#\"))\n",
        "                heading_text = stripped.lstrip(\"#\").strip()\n",
        "                if level <= len(heading_stack):\n",
        "                    heading_stack[:] = heading_stack[:level - 1]\n",
        "                heading_stack.append(heading_text)\n",
        "                units.append({\"type\": \"text\", \"text\": heading_text, \"headings\": heading_stack.copy()})\n",
        "                continue\n",
        "\n",
        "            image_match = IMAGE_PATTERN.search(stripped)\n",
        "            if image_match:\n",
        "                flush_para()\n",
        "                raw_path = image_match.group(\"path\").strip()\n",
        "                normalized_name, page_num = self._normalize_filename(raw_path, images_dir)\n",
        "                caption = self._find_caption(lines, idx)\n",
        "                image_info = ImageInfo(filename=normalized_name, caption=caption, page=page_num)\n",
        "                placeholder = caption or f\"Image {normalized_name}\"\n",
        "                units.append({\"type\": \"figure\", \"text\": f\"[Figure] {placeholder}\", \"images\": [image_info], \"headings\": heading_stack.copy()})\n",
        "                continue\n",
        "\n",
        "            if stripped == \"\":\n",
        "                flush_para()\n",
        "            else:\n",
        "                current_para.append(stripped)\n",
        "        flush_para()\n",
        "\n",
        "        chunks = []\n",
        "        buf_units, buf_images, buf_headings = [], [], []\n",
        "        current_len = 0\n",
        "\n",
        "        def flush_chunk():\n",
        "            nonlocal buf_units, buf_images, buf_headings, current_len\n",
        "            if not buf_units: return\n",
        "            text = \"\\n\\n\".join(u[\"text\"] for u in buf_units).strip()\n",
        "            chunks.append(Chunk(index=len(chunks), text=text, images=list(buf_images), headings=list(buf_headings)))\n",
        "            overlap_chars = int(self.max_chars * self.overlap_ratio)\n",
        "            carry_units, carry_len = [], 0\n",
        "            for u in reversed(buf_units):\n",
        "                u_len = len(u.get(\"text\", \"\"))\n",
        "                if carry_len + u_len > overlap_chars: break\n",
        "                if u.get(\"type\") == \"figure\": break\n",
        "                carry_units.insert(0, u)\n",
        "                carry_len += u_len + 2\n",
        "            buf_units[:] = carry_units\n",
        "            buf_images[:] = []\n",
        "            buf_headings[:] = list(buf_headings)\n",
        "            current_len = carry_len\n",
        "\n",
        "        for unit in units:\n",
        "            unit_text = unit.get(\"text\", \"\").strip()\n",
        "            if not unit_text: continue\n",
        "            unit_len = len(unit_text)\n",
        "            if current_len + unit_len > self.max_chars and buf_units:\n",
        "                flush_chunk()\n",
        "            buf_units.append(unit)\n",
        "            buf_images.extend(unit.get(\"images\", []))\n",
        "            if unit.get(\"headings\"): buf_headings[:] = unit[\"headings\"]\n",
        "            current_len += unit_len + 2\n",
        "        flush_chunk()\n",
        "        return chunks\n",
        "\n",
        "    def _normalize_filename(self, raw_path, images_dir):\n",
        "        raw_name = Path(raw_path).name\n",
        "        stem = Path(raw_name).stem\n",
        "        for ext in (\".png\", \".jpeg\", \".jpg\"):\n",
        "            candidate = images_dir / f\"{stem}{ext}\"\n",
        "            if candidate.exists():\n",
        "                return candidate.name, self._extract_page(stem)\n",
        "        return raw_name, self._extract_page(stem)\n",
        "\n",
        "    def _extract_page(self, stem):\n",
        "        match = re.search(r\"_page_(\\d+)_\", stem)\n",
        "        return int(match.group(1)) if match else None\n",
        "\n",
        "    def _find_caption(self, lines, idx):\n",
        "        for offset in [-2, -1, 1, 2]:\n",
        "            pos = idx + offset\n",
        "            if 0 <= pos < len(lines):\n",
        "                match = CAPTION_PATTERN.match(lines[pos].strip())\n",
        "                if match: return match.group(\"caption\").strip()\n",
        "        return None\n",
        "\n",
        "# Run chunker\n",
        "chunker = BookChunker(max_chars=CHUNK_SIZE, overlap_ratio=OVERLAP_RATIO)\n",
        "chunks = chunker.chunk_markdown(md_path, images_dir)\n",
        "\n",
        "total_images = sum(len(c.images) for c in chunks)\n",
        "print(f\"‚úÖ Chunked into {len(chunks)} chunks\")\n",
        "print(f\"   Avg chunk size: {sum(len(c.text) for c in chunks) // max(len(chunks), 1)} chars\")\n",
        "print(f\"   Chunks with images: {sum(1 for c in chunks if c.images)}\")\n",
        "print(f\"   Total image references: {total_images}\")\n",
        "\n",
        "# Preview first chunk\n",
        "if chunks:\n",
        "    print(f\"\\n--- Chunk 0 Preview ---\")\n",
        "    print(chunks[0].text[:300])\n",
        "    if chunks[0].images:\n",
        "        print(f\"  Images: {[i.filename for i in chunks[0].images]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Send to GraphRecall Backend\n",
        "\n",
        "Sends the chunked book through the `/api/v2/ingest` endpoint.\n",
        "The backend will: embed, extract concepts, build graph, generate flashcards & quizzes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import json\nimport time\nimport requests\n\n# Reassemble full content\nfull_markdown = markdown_text\n\nprint(f\"üöÄ Sending '{BOOK_TITLE}' to GraphRecall...\")\nprint(f\"   Content length: {len(full_markdown):,} chars\")\nprint(f\"   Backend: {BACKEND_URL}\")\nprint(\"-\" * 50)\nprint(\"‚è≥ Uploading... this will take a few minutes as the backend processes batches...\")\n\npayload = {\n    \"content\": full_markdown,\n    \"title\": BOOK_TITLE,\n    \"skip_review\": SKIP_REVIEW,\n    \"resource_type\": \"book\",\n}\n\ntry:\n    # Increased timeout because backend processing can take several minutes.\n    resp = requests.post(\n        f\"{BACKEND_URL}/api/v2/ingest\",\n        headers=HEADERS,\n        json=payload,\n        timeout=600,\n    )\n\n    if resp.status_code == 200:\n        result = resp.json()\n        note_id = result.get(\"note_id\")\n        concepts = result.get(\"concepts\", [])\n        flashcards = result.get(\"flashcard_ids\", [])\n\n        print(\"‚úÖ Ingestion complete!\")\n        print(f\"   Note ID: {note_id}\")\n        print(f\"   Concepts Extracted: {len(concepts)}\")\n        print(f\"   Flashcards Created: {len(flashcards)}\")\n\n        # Keep this as a list for the verification step.\n        note_ids = [note_id] if note_id else []\n    else:\n        print(f\"‚ùå Failed (HTTP {resp.status_code})\")\n        print(resp.text[:1000])\n        note_ids = []\n\nexcept Exception as e:\n    print(f\"‚ùå Connection Error: {e}\")\n    print(\"If this was a 'Read Timeout', the backend may still be processing. Check backend logs.\")\n    note_ids = []"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 6: Verify Ingestion\n\nChecks that chunks, embeddings, and concepts were actually created."
    },
    {
      "cell_type": "code",
      "source": "print(\"üîç Verifying ingestion...\")\nprint(\"-\" * 50)\n\nall_ok = True\n\nfor nid in note_ids:\n    if not nid:\n        continue\n    try:\n        # Check note exists\n        resp = requests.get(\n            f\"{BACKEND_URL}/api/notes/{nid}\",\n            headers=HEADERS,\n            timeout=10,\n        )\n        if resp.status_code == 200:\n            note = resp.json()\n            title = note.get(\"title\", \"?\")\n            print(f\"‚úÖ Note: {title}\")\n        else:\n            print(f\"‚ö†Ô∏è Note {nid}: HTTP {resp.status_code}\")\n            all_ok = False\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Note {nid}: {e}\")\n        all_ok = False\n\n# Check graph stats\ntry:\n    resp = requests.get(\n        f\"{BACKEND_URL}/api/graph3d/\",\n        headers=HEADERS,\n        timeout=15,\n    )\n    if resp.status_code == 200:\n        graph = resp.json()\n        nodes = len(graph.get(\"nodes\", []))\n        edges = len(graph.get(\"edges\", []))\n        print(f\"‚úÖ Knowledge Graph: {nodes} concepts, {edges} relationships\")\n        if nodes == 0:\n            print(\"   ‚ö†Ô∏è No concepts in graph ‚Äî ingestion may have failed silently\")\n            all_ok = False\n    else:\n        print(f\"‚ö†Ô∏è Graph API: HTTP {resp.status_code}\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Graph check: {e}\")\n\nif all_ok:\n    print(f\"\\nüéâ Ingestion verified successfully!\")\nelse:\n    print(f\"\\n‚ö†Ô∏è Some checks failed. Check Render logs for errors.\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîÑ Recomputing communities...\")\n",
        "try:\n",
        "    resp = requests.post(\n",
        "        f\"{BACKEND_URL}/api/graph3d/communities/recompute\",\n",
        "        headers=HEADERS,\n",
        "        timeout=120,\n",
        "    )\n",
        "    if resp.status_code == 200:\n",
        "        result = resp.json()\n",
        "        print(f\"‚úÖ Communities recomputed: {result.get('num_communities', '?')} communities\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Community recompute returned {resp.status_code}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Failed: {e} (not critical, communities will be computed on next app load)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Done!\n",
        "\n",
        "Your book is now in GraphRecall. Open the app to:\n",
        "- üåê See new concepts in the Knowledge Graph\n",
        "- üìö Browse the book in Library\n",
        "- üß† Study with auto-generated flashcards & quizzes\n",
        "- üí¨ Ask the AI assistant about the book's content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Download the markdown + images locally too\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "zip_path = f\"/content/{pdf_path.stem}_extracted\"\n",
        "shutil.make_archive(zip_path, 'zip', output_dir)\n",
        "print(f\"üì¶ Download backup: {zip_path}.zip\")\n",
        "files.download(f\"{zip_path}.zip\")"
      ]
    }
  ]
}
