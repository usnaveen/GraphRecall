{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö GraphRecall Book Ingestion Pipeline\n",
    "\n",
    "**All-in-one notebook**: PDF ‚Üí Marker OCR ‚Üí Chunking ‚Üí API Ingestion\n",
    "\n",
    "This notebook is a **backdoor** into GraphRecall. It:\n",
    "1. üìÑ Converts PDF to Markdown using Marker (GPU-accelerated)\n",
    "2. ‚úÇÔ∏è Chunks the markdown with image-aware, heading-preserving chunker\n",
    "3. üß† Sends chunks to your GraphRecall backend API for full processing\n",
    "4. üìä Extracts concepts, builds knowledge graph, generates flashcards & quizzes\n",
    "\n",
    "**Requirements:**\n",
    "- Colab GPU runtime (T4 or better)\n",
    "- Your GraphRecall backend URL and auth token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install marker-pdf requests -q\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configuration\n",
    "\n",
    "Set your GraphRecall backend URL and authentication details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ‚öôÔ∏è CONFIGURATION - Edit these values\n",
    "# ============================================================\n",
    "\n",
    "# Your GraphRecall backend URL (no trailing slash)\n",
    "BACKEND_URL = \"https://your-graphrecall-backend.com\"  # ‚¨ÖÔ∏è EDIT THIS\n",
    "\n",
    "# Auth: paste your Google OAuth access token here.\n",
    "# Get it from: browser DevTools > Application > Cookies > access_token\n",
    "AUTH_TOKEN = \"\"  # ‚¨ÖÔ∏è PASTE YOUR TOKEN\n",
    "\n",
    "# Book metadata\n",
    "BOOK_TITLE = \"\"  # ‚¨ÖÔ∏è e.g., \"Introduction to Machine Learning\"\n",
    "\n",
    "# Chunking config\n",
    "CHUNK_SIZE = 1400  # Max chars per chunk\n",
    "OVERLAP_RATIO = 0.15  # 15% overlap between chunks\n",
    "\n",
    "# Processing options\n",
    "SKIP_REVIEW = True  # Auto-approve concepts (recommended for books)\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "import requests\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {AUTH_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "# Verify connection\n",
    "try:\n",
    "    resp = requests.get(f\"{BACKEND_URL}/api/v2/health\", headers=HEADERS, timeout=10)\n",
    "    if resp.status_code == 200:\n",
    "        print(f\"‚úÖ Connected to GraphRecall at {BACKEND_URL}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Backend returned status {resp.status_code}\")\n",
    "        print(f\"   Response: {resp.text[:200]}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Cannot reach backend: {e}\")\n",
    "    print(\"   Make sure your backend is running and the URL is correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Upload PDF & Run Marker OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU. Go to Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload PDF\n",
    "UPLOAD_METHOD = \"direct\"  # Change to \"drive\" for Google Drive\n",
    "\n",
    "if UPLOAD_METHOD == \"direct\":\n",
    "    from google.colab import files\n",
    "    print(\"üìÅ Select your PDF file...\")\n",
    "    uploaded = files.upload()\n",
    "    PDF_PATH = list(uploaded.keys())[0]\n",
    "    if not BOOK_TITLE:\n",
    "        BOOK_TITLE = PDF_PATH.rsplit('.', 1)[0]\n",
    "    print(f\"‚úÖ Uploaded: {PDF_PATH}\")\n",
    "else:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    PDF_PATH = \"/content/drive/MyDrive/Your_Book.pdf\"  # ‚¨ÖÔ∏è EDIT THIS\n",
    "    if not BOOK_TITLE:\n",
    "        BOOK_TITLE = PDF_PATH.rsplit('/', 1)[-1].rsplit('.', 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time\nfrom pathlib import Path\n\nfrom marker.converters.pdf import PdfConverter\nfrom marker.models import create_model_dict\nfrom marker.output import text_from_rendered\n\npdf_path = Path(PDF_PATH)\nprint(f\"üìñ Processing: {pdf_path.name} ({pdf_path.stat().st_size / 1024 / 1024:.1f} MB)\")\nprint(\"-\" * 50)\n\nstart_time = time.time()\n\nprint(\"üîß Loading OCR models...\")\nmodel_dict = create_model_dict()\nconverter = PdfConverter(artifact_dict=model_dict)\n\nprint(\"üìù Extracting text and images...\")\nrendered = converter(str(pdf_path))\nmarkdown_text, _, images = text_from_rendered(rendered)\n\nelapsed = time.time() - start_time\nprint(f\"‚úÖ OCR complete in {elapsed:.1f}s\")\nprint(f\"   Text: {len(markdown_text):,} chars | Images: {len(images) if images else 0}\")\n\n# Save images locally\noutput_dir = Path(f\"/content/{pdf_path.stem}_output\")\noutput_dir.mkdir(exist_ok=True)\nimages_dir = output_dir / \"images\"\nimages_dir.mkdir(exist_ok=True)\n\nsaved_count = 0\nfailed_count = 0\nif images:\n    from PIL import Image\n    for img_name, img_data in images.items():\n        img_path = images_dir / img_name\n        try:\n            if isinstance(img_data, bytes):\n                img_path.write_bytes(img_data)\n            elif hasattr(img_data, 'save'):\n                # Handle both PIL.Image and Marker's RenderedImage objects.\n                # Newer Marker versions may wrap images ‚Äî extract the PIL image\n                # if the direct .save() call fails due to extra arguments.\n                pil_img = img_data\n                if hasattr(img_data, 'image'):\n                    pil_img = img_data.image  # RenderedImage wrapper\n                elif not isinstance(img_data, Image.Image):\n                    # Try converting to PIL Image as fallback\n                    pil_img = Image.frombytes(img_data.mode, img_data.size, img_data.tobytes())\n                pil_img.save(str(img_path))\n            else:\n                # Last resort: try writing raw bytes\n                with open(img_path, 'wb') as f:\n                    f.write(bytes(img_data))\n            saved_count += 1\n        except Exception as e:\n            failed_count += 1\n            print(f\"  ‚ö†Ô∏è Failed to save {img_name}: {e}\")\n    print(f\"   Saved {saved_count} images to {images_dir}\")\n    if failed_count:\n        print(f\"   ‚ö†Ô∏è {failed_count} images failed (non-critical, text extraction still works)\")\n\n# Save markdown\nmd_path = output_dir / f\"{pdf_path.stem}.md\"\nmd_path.write_text(markdown_text, encoding=\"utf-8\")\nprint(f\"   Saved markdown to {md_path}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Chunk the Book\n",
    "\n",
    "Uses GraphRecall's image-aware BookChunker: detects figures, preserves headings, smart overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "\n",
    "# ============================================================\n",
    "# BookChunker (copied from backend/services/book_chunker.py)\n",
    "# ============================================================\n",
    "\n",
    "IMAGE_PATTERN = re.compile(r\"!\\[[^\\]]*\\]\\((?P<path>[^)]+)\\)\")\n",
    "CAPTION_PATTERN = re.compile(r\"^(Figure|Fig\\.?|FIGURE)\\s+[\\w\\.\\-]+[:\\.']?\\s*(?P<caption>.+)$\")\n",
    "\n",
    "@dataclass\n",
    "class ImageInfo:\n",
    "    filename: str\n",
    "    caption: Optional[str]\n",
    "    page: Optional[int]\n",
    "    url: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    index: int\n",
    "    text: str\n",
    "    images: List[ImageInfo] = field(default_factory=list)\n",
    "    headings: List[str] = field(default_factory=list)\n",
    "\n",
    "class BookChunker:\n",
    "    def __init__(self, max_chars=1400, overlap_ratio=0.15):\n",
    "        self.max_chars = max_chars\n",
    "        self.overlap_ratio = overlap_ratio\n",
    "\n",
    "    def chunk_markdown(self, md_path, images_dir):\n",
    "        lines = md_path.read_text(encoding=\"utf-8\").splitlines()\n",
    "        return self._chunk_lines(lines, images_dir)\n",
    "\n",
    "    def _chunk_lines(self, lines, images_dir):\n",
    "        units = []\n",
    "        current_para = []\n",
    "        heading_stack = []\n",
    "\n",
    "        def flush_para():\n",
    "            if current_para:\n",
    "                text = \"\\n\".join(current_para).strip()\n",
    "                if text:\n",
    "                    units.append({\"type\": \"text\", \"text\": text, \"headings\": heading_stack.copy()})\n",
    "                current_para.clear()\n",
    "\n",
    "        for idx, line in enumerate(lines):\n",
    "            stripped = line.strip()\n",
    "            if stripped.startswith(\"#\"):\n",
    "                flush_para()\n",
    "                level = len(stripped) - len(stripped.lstrip(\"#\"))\n",
    "                heading_text = stripped.lstrip(\"#\").strip()\n",
    "                if level <= len(heading_stack):\n",
    "                    heading_stack[:] = heading_stack[:level - 1]\n",
    "                heading_stack.append(heading_text)\n",
    "                units.append({\"type\": \"text\", \"text\": heading_text, \"headings\": heading_stack.copy()})\n",
    "                continue\n",
    "\n",
    "            image_match = IMAGE_PATTERN.search(stripped)\n",
    "            if image_match:\n",
    "                flush_para()\n",
    "                raw_path = image_match.group(\"path\").strip()\n",
    "                normalized_name, page_num = self._normalize_filename(raw_path, images_dir)\n",
    "                caption = self._find_caption(lines, idx)\n",
    "                image_info = ImageInfo(filename=normalized_name, caption=caption, page=page_num)\n",
    "                placeholder = caption or f\"Image {normalized_name}\"\n",
    "                units.append({\"type\": \"figure\", \"text\": f\"[Figure] {placeholder}\", \"images\": [image_info], \"headings\": heading_stack.copy()})\n",
    "                continue\n",
    "\n",
    "            if stripped == \"\":\n",
    "                flush_para()\n",
    "            else:\n",
    "                current_para.append(stripped)\n",
    "        flush_para()\n",
    "\n",
    "        chunks = []\n",
    "        buf_units, buf_images, buf_headings = [], [], []\n",
    "        current_len = 0\n",
    "\n",
    "        def flush_chunk():\n",
    "            nonlocal buf_units, buf_images, buf_headings, current_len\n",
    "            if not buf_units: return\n",
    "            text = \"\\n\\n\".join(u[\"text\"] for u in buf_units).strip()\n",
    "            chunks.append(Chunk(index=len(chunks), text=text, images=list(buf_images), headings=list(buf_headings)))\n",
    "            overlap_chars = int(self.max_chars * self.overlap_ratio)\n",
    "            carry_units, carry_len = [], 0\n",
    "            for u in reversed(buf_units):\n",
    "                u_len = len(u.get(\"text\", \"\"))\n",
    "                if carry_len + u_len > overlap_chars: break\n",
    "                if u.get(\"type\") == \"figure\": break\n",
    "                carry_units.insert(0, u)\n",
    "                carry_len += u_len + 2\n",
    "            buf_units[:] = carry_units\n",
    "            buf_images[:] = []\n",
    "            buf_headings[:] = list(buf_headings)\n",
    "            current_len = carry_len\n",
    "\n",
    "        for unit in units:\n",
    "            unit_text = unit.get(\"text\", \"\").strip()\n",
    "            if not unit_text: continue\n",
    "            unit_len = len(unit_text)\n",
    "            if current_len + unit_len > self.max_chars and buf_units:\n",
    "                flush_chunk()\n",
    "            buf_units.append(unit)\n",
    "            buf_images.extend(unit.get(\"images\", []))\n",
    "            if unit.get(\"headings\"): buf_headings[:] = unit[\"headings\"]\n",
    "            current_len += unit_len + 2\n",
    "        flush_chunk()\n",
    "        return chunks\n",
    "\n",
    "    def _normalize_filename(self, raw_path, images_dir):\n",
    "        raw_name = Path(raw_path).name\n",
    "        stem = Path(raw_name).stem\n",
    "        for ext in (\".png\", \".jpeg\", \".jpg\"):\n",
    "            candidate = images_dir / f\"{stem}{ext}\"\n",
    "            if candidate.exists():\n",
    "                return candidate.name, self._extract_page(stem)\n",
    "        return raw_name, self._extract_page(stem)\n",
    "\n",
    "    def _extract_page(self, stem):\n",
    "        match = re.search(r\"_page_(\\d+)_\", stem)\n",
    "        return int(match.group(1)) if match else None\n",
    "\n",
    "    def _find_caption(self, lines, idx):\n",
    "        for offset in [-2, -1, 1, 2]:\n",
    "            pos = idx + offset\n",
    "            if 0 <= pos < len(lines):\n",
    "                match = CAPTION_PATTERN.match(lines[pos].strip())\n",
    "                if match: return match.group(\"caption\").strip()\n",
    "        return None\n",
    "\n",
    "# Run chunker\n",
    "chunker = BookChunker(max_chars=CHUNK_SIZE, overlap_ratio=OVERLAP_RATIO)\n",
    "chunks = chunker.chunk_markdown(md_path, images_dir)\n",
    "\n",
    "total_images = sum(len(c.images) for c in chunks)\n",
    "print(f\"‚úÖ Chunked into {len(chunks)} chunks\")\n",
    "print(f\"   Avg chunk size: {sum(len(c.text) for c in chunks) // max(len(chunks), 1)} chars\")\n",
    "print(f\"   Chunks with images: {sum(1 for c in chunks if c.images)}\")\n",
    "print(f\"   Total image references: {total_images}\")\n",
    "\n",
    "# Preview first chunk\n",
    "if chunks:\n",
    "    print(f\"\\n--- Chunk 0 Preview ---\")\n",
    "    print(chunks[0].text[:300])\n",
    "    if chunks[0].images:\n",
    "        print(f\"  Images: {[i.filename for i in chunks[0].images]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Send to GraphRecall Backend\n",
    "\n",
    "Sends the chunked book through the `/api/v2/ingest` endpoint.\n",
    "The backend will: embed, extract concepts, build graph, generate flashcards & quizzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport time\n\n# Reassemble chunks into a single markdown with page markers for the backend\n# The backend's BookChunker will re-chunk, but we include heading context\nfull_markdown = markdown_text\n\nprint(f\"üöÄ Sending '{BOOK_TITLE}' to GraphRecall...\")\nprint(f\"   Content length: {len(full_markdown):,} chars\")\nprint(f\"   Backend: {BACKEND_URL}\")\nprint(\"-\" * 50)\n\n# Split into manageable batches if very large (>50k chars)\nMAX_BATCH_SIZE = 50000\n\ntotal_concepts = 0\ntotal_flashcards = 0\nnote_ids = []\nall_errors = []\n\nif len(full_markdown) <= MAX_BATCH_SIZE:\n    # Single ingestion call\n    payload = {\n        \"content\": full_markdown,\n        \"title\": BOOK_TITLE,\n        \"skip_review\": SKIP_REVIEW,\n        \"resource_type\": \"book\",\n    }\n    resp = requests.post(\n        f\"{BACKEND_URL}/api/v2/ingest\",\n        headers=HEADERS,\n        json=payload,\n        timeout=300,\n    )\n    if resp.status_code == 200:\n        result = resp.json()\n        note_ids.append(result.get('note_id'))\n        total_concepts = len(result.get('concepts', []))\n        total_flashcards = len(result.get('flashcard_ids', []))\n        print(f\"‚úÖ Ingestion complete!\")\n        print(f\"   Note ID: {result.get('note_id')}\")\n        print(f\"   Concepts: {total_concepts}\")\n        print(f\"   Flashcards: {total_flashcards}\")\n        print(f\"   Status: {result.get('status')}\")\n        if result.get('error'):\n            all_errors.append(result['error'])\n            print(f\"   ‚ö†Ô∏è Error: {result['error']}\")\n    else:\n        print(f\"‚ùå Failed: {resp.status_code}\")\n        print(resp.text[:500])\n        all_errors.append(f\"HTTP {resp.status_code}: {resp.text[:200]}\")\nelse:\n    # Batch ingestion for large books\n    # Split by chunks and send in batches\n    batch_size = 15  # chunks per batch\n    \n    for i in range(0, len(chunks), batch_size):\n        batch = chunks[i:i + batch_size]\n        batch_text = \"\\n\\n\".join(c.text for c in batch)\n        batch_num = i // batch_size + 1\n        total_batches = (len(chunks) + batch_size - 1) // batch_size\n\n        print(f\"  Batch {batch_num}/{total_batches} ({len(batch)} chunks, {len(batch_text):,} chars)...\")\n\n        payload = {\n            \"content\": batch_text,\n            \"title\": f\"{BOOK_TITLE} (Part {batch_num})\",\n            \"skip_review\": SKIP_REVIEW,\n            \"resource_type\": \"book\",\n        }\n        try:\n            resp = requests.post(\n                f\"{BACKEND_URL}/api/v2/ingest\",\n                headers=HEADERS,\n                json=payload,\n                timeout=300,\n            )\n            if resp.status_code == 200:\n                result = resp.json()\n                nc = len(result.get('concepts', []))\n                nf = len(result.get('flashcard_ids', []))\n                total_concepts += nc\n                total_flashcards += nf\n                note_ids.append(result.get('note_id'))\n                print(f\"    ‚úÖ +{nc} concepts, +{nf} flashcards\")\n                if result.get('error'):\n                    all_errors.append(f\"Batch {batch_num}: {result['error']}\")\n                    print(f\"    ‚ö†Ô∏è {result['error']}\")\n            else:\n                err = f\"Batch {batch_num}: HTTP {resp.status_code} - {resp.text[:200]}\"\n                all_errors.append(err)\n                print(f\"    ‚ùå Failed: {resp.status_code} - {resp.text[:200]}\")\n        except Exception as e:\n            all_errors.append(f\"Batch {batch_num}: {e}\")\n            print(f\"    ‚ùå Error: {e}\")\n\n        time.sleep(2)  # Rate limiting\n\n    print(f\"\\n‚úÖ Book ingestion complete!\")\n    print(f\"   Total concepts: {total_concepts}\")\n    print(f\"   Total flashcards: {total_flashcards}\")\n    print(f\"   Note parts: {len(note_ids)}\")\n\nif all_errors:\n    print(f\"\\n‚ö†Ô∏è {len(all_errors)} warnings/errors during ingestion:\")\n    for err in all_errors[:5]:\n        print(f\"   - {err}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 6: Verify Ingestion\n\nChecks that chunks, embeddings, and concepts were actually created."
  },
  {
   "cell_type": "code",
   "source": "print(\"üîç Verifying ingestion...\")\nprint(\"-\" * 50)\n\nall_ok = True\n\nfor nid in note_ids:\n    if not nid:\n        continue\n    try:\n        # Check note exists\n        resp = requests.get(\n            f\"{BACKEND_URL}/api/notes/{nid}\",\n            headers=HEADERS,\n            timeout=10,\n        )\n        if resp.status_code == 200:\n            note = resp.json()\n            title = note.get(\"title\", \"?\")\n            print(f\"‚úÖ Note: {title}\")\n        else:\n            print(f\"‚ö†Ô∏è Note {nid}: HTTP {resp.status_code}\")\n            all_ok = False\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Note {nid}: {e}\")\n        all_ok = False\n\n# Check graph stats\ntry:\n    resp = requests.get(\n        f\"{BACKEND_URL}/api/graph3d/\",\n        headers=HEADERS,\n        timeout=15,\n    )\n    if resp.status_code == 200:\n        graph = resp.json()\n        nodes = len(graph.get(\"nodes\", []))\n        edges = len(graph.get(\"edges\", []))\n        print(f\"‚úÖ Knowledge Graph: {nodes} concepts, {edges} relationships\")\n        if nodes == 0:\n            print(\"   ‚ö†Ô∏è No concepts in graph ‚Äî ingestion may have failed silently\")\n            all_ok = False\n    else:\n        print(f\"‚ö†Ô∏è Graph API: HTTP {resp.status_code}\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Graph check: {e}\")\n\nif all_ok:\n    print(f\"\\nüéâ Ingestion verified successfully!\")\nelse:\n    print(f\"\\n‚ö†Ô∏è Some checks failed. Check Render logs for errors.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Recomputing communities...\")\n",
    "try:\n",
    "    resp = requests.post(\n",
    "        f\"{BACKEND_URL}/api/graph3d/communities/recompute\",\n",
    "        headers=HEADERS,\n",
    "        timeout=120,\n",
    "    )\n",
    "    if resp.status_code == 200:\n",
    "        result = resp.json()\n",
    "        print(f\"‚úÖ Communities recomputed: {result.get('num_communities', '?')} communities\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Community recompute returned {resp.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Failed: {e} (not critical, communities will be computed on next app load)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Done!\n",
    "\n",
    "Your book is now in GraphRecall. Open the app to:\n",
    "- üåê See new concepts in the Knowledge Graph\n",
    "- üìö Browse the book in Library\n",
    "- üß† Study with auto-generated flashcards & quizzes\n",
    "- üí¨ Ask the AI assistant about the book's content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Download the markdown + images locally too\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "zip_path = f\"/content/{pdf_path.stem}_extracted\"\n",
    "shutil.make_archive(zip_path, 'zip', output_dir)\n",
    "print(f\"üì¶ Download backup: {zip_path}.zip\")\n",
    "files.download(f\"{zip_path}.zip\")"
   ]
  }
 ]
}