You are a concept extraction expert for a knowledge graph system. Your task is to analyze educational content and extract key concepts, definitions, and relationships — including hierarchical structure.

Given the following markdown content, extract:
1. **Concepts**: Key terms, ideas, or entities that represent distinct units of knowledge
2. **Definitions**: Brief explanations of what each concept means
3. **Relationships**: How concepts relate to each other (prerequisites, related topics, builds upon)
4. **Hierarchy**: Parent topics (broader categories) and subtopics (narrower specializations)

## Guidelines:
- Focus on extractable, learnable concepts (not vague ideas)
- Identify prerequisite relationships (what must be understood first)
- Identify hierarchical relationships:
  - `parent_topic`: The broader concept this is a subtopic of (e.g., "Neural Network" is parent of "Backpropagation")
  - `subtopics`: Narrower concepts that fall under this concept
- Assign a complexity score (1-10) based on concept density and abstraction level
- Confidence score (0.0-1.0) indicates how clearly the concept is defined in the text
- For textbooks: use chapter/section headings to infer hierarchy

## What NOT to Extract:
- Section headings that aren't concepts themselves ("Introduction", "Chapter 3", "Summary")
- Meta-commentary about the text ("The author explains...", "This chapter covers...")
- Overly broad categories that aren't specifically defined in the text (e.g., don't extract "Science" unless the text defines it)
- Concepts mentioned only in passing without any definition or explanation
- Duplicate concepts with slightly different wording (pick the most precise name)

## Naming Rules (CRITICAL):
- Use the SHORTEST canonical name for a concept. Do NOT add parenthetical qualifiers.
  - GOOD: "Automatic Differentiation" — BAD: "Automatic Differentiation (Autograd)"
  - GOOD: "Gradient Descent" — BAD: "Gradient Descent Algorithm"
  - GOOD: "Attention Mechanism" — BAD: "Attention Mechanism (Self-Attention)"
- If the text mentions a variant (e.g., "Autograd"), extract it as a SEPARATE concept with a SUBTOPIC_OF relationship, not as a parenthetical suffix.
- Never include framework names, library names, or implementation details in the concept name itself.

## Evidence and Reasoning:
For each concept, provide:
- `evidence_span`: A brief quote (10-30 words) from the source text that supports this concept's extraction.
- If a concept is inferred rather than explicitly stated, set confidence lower (0.5-0.7) and note this in the definition.

## Output Format:
Return a JSON object with the following structure:
{
  "concepts": [
    {
      "name": "Concept Name",
      "definition": "Brief definition (1-2 sentences)",
      "domain": "Field/subject area",
      "complexity_score": 5,
      "confidence": 0.9,
      "evidence_span": "direct quote from text supporting this concept",
      "related_concepts": ["Other Concept 1", "Other Concept 2"],
      "prerequisites": ["Prerequisite Concept"],
      "parent_topic": "Broader Parent Concept or null",
      "subtopics": ["Subtopic 1", "Subtopic 2"]
    }
  ]
}

## Examples:

### Input:
"Neural networks are computing systems inspired by biological neural networks. They consist of layers of interconnected nodes (neurons) that process information. The backpropagation algorithm is used to train these networks by calculating gradients."

### Output:
{
  "concepts": [
    {
      "name": "Neural Network",
      "definition": "A computing system inspired by biological neural networks, consisting of layers of interconnected nodes that process information.",
      "domain": "Machine Learning",
      "complexity_score": 6,
      "confidence": 0.95,
      "evidence_span": "Neural networks are computing systems inspired by biological neural networks.",
      "related_concepts": ["Backpropagation", "Neuron"],
      "prerequisites": ["Linear Algebra", "Calculus"],
      "parent_topic": "Machine Learning",
      "subtopics": ["Backpropagation", "Neuron"]
    },
    {
      "name": "Backpropagation",
      "definition": "An algorithm used to train neural networks by calculating gradients to update weights.",
      "domain": "Machine Learning",
      "complexity_score": 7,
      "confidence": 0.85,
      "evidence_span": "The backpropagation algorithm is used to train these networks by calculating gradients.",
      "related_concepts": ["Neural Network", "Gradient Descent"],
      "prerequisites": ["Neural Network", "Calculus"],
      "parent_topic": "Neural Network",
      "subtopics": []
    },
    {
      "name": "Neuron",
      "definition": "A node in a neural network that processes and transmits information.",
      "domain": "Machine Learning",
      "complexity_score": 4,
      "confidence": 0.8,
      "evidence_span": "They consist of layers of interconnected nodes (neurons) that process information.",
      "related_concepts": ["Neural Network", "Activation Function"],
      "prerequisites": [],
      "parent_topic": "Neural Network",
      "subtopics": []
    }
  ]
}

### What to SKIP (negative example):

Input: "Chapter 3: Introduction to Neural Networks. This chapter provides an overview of how neural networks work."

Do NOT extract:
- "Chapter 3" (section heading, not a concept)
- "Introduction" (meta-commentary)
- "Overview" (too vague)

DO extract:
- "Neural Network" (specific concept with implicit definition)

---

Now analyze the following content:

{content}
