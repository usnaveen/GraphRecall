
import json
import structlog
from typing import List, Optional
from pydantic import BaseModel

from backend.config.llm import get_fast_model
from backend.db.postgres_client import get_postgres_client

logger = structlog.get_logger()

class QuizCandidateSchema(BaseModel):
    topic: str
    chunk_text: str
    difficulty: float
    reasoning: str

class ScannerAgent:
    """
    Scans content to identify potential quiz topics without generating full questions yet.
    This enables 'Lazy Generation' to save tokens.
    """

    def __init__(self):
        self.llm = get_fast_model(temperature=0.1, json_mode=True)

    async def scan_and_save(self, text: str, source_note_id: str, user_id: str) -> int:
        """
        Scans text for quiz candidates and saves them.
        Returns number of candidates found.
        """
        if not text or len(text) < 100:
            return 0

        logger.info("ScannerAgent: Scanning content", source_note_id=source_note_id, text_len=len(text))

        prompt = f"""You are a content analyzer for an educational app.
Analyze the following text and identify distinct TOPICS that would make good quiz questions.
For each topic, extract a specific 'chunk' of text that contains the answer or context needed.

CRITERIA:
- Topics should be specific concepts (e.g., 'Photosynthesis Process' not just 'Biology').
- Chunks should be concise (1-3 sentences).
- Difficulty: 0.1 (Easy) to 1.0 (Hard).

TEXT TO ANALYZE:
{text[:15000]}  # Limit context window just in case

OUTPUT JSON:
{{
    "candidates": [
        {{
            "topic": "Specific Topic Name",
            "chunk_text": "Exact quote or summary of the fact...",
            "difficulty": 0.5,
            "reasoning": "This sentence defines X..."
        }}
    ]
}}"""
        
        try:
            response = await self.llm.ainvoke(prompt)
            content = response.content
            
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            
            data = json.loads(content)
            candidates = data.get("candidates", [])
            
            if not candidates:
                return 0

            pg_client = await get_postgres_client()
            
            # Batch insert
            # We construct values list for efficiency
            # ID is generated by DB default
            
            count = 0
            for c in candidates:
                await pg_client.execute_insert(
                    """
                    INSERT INTO quiz_candidates (user_id, source_note_id, topic, chunk_text, difficulty, status)
                    VALUES (:user_id, :note_id, :topic, :chunk, :diff, 'pending')
                    """,
                    {
                        "user_id": user_id,
                        "note_id": source_note_id,
                        "topic": c["topic"],
                        "chunk": c["chunk_text"],
                        "diff": c["difficulty"]
                    }
                )
                count += 1
                
            logger.info("ScannerAgent: Saved candidates", count=count)
            return count

        except Exception as e:
            logger.error("ScannerAgent: Scan failed", error=str(e))
            return 0
